{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DES LIBRAIRIE\n",
    "\n",
    "import speech_recognition as sr\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.training.example import offsets_to_biluo_tags\n",
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "from spacy.util import minibatch, compounding\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLE\n",
    "\n",
    "r = sr.Recognizer()\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "\n",
    "# Liste des mots pour reconnaître la destination en première\n",
    "destination_keywords = [\n",
    "    \"à\",\n",
    "    \"vers\",\n",
    "    \"jusqu'à\",\n",
    "    \"pour\",\n",
    "    \"en direction de\",\n",
    "    \"jusqu'à chez\",\n",
    "] \n",
    "# Liste des mots pour reconnaître la departure en première\n",
    "departure_keywords = [\n",
    "    \"depuis\",\n",
    "    \"de\",\n",
    "    \"au départ de\",\n",
    "    \"en partant de\",\n",
    "    \"depuis\",\n",
    "    \"au départ de chez\",\n",
    "]\n",
    "# Liste des mots pour reconnaître les passage\n",
    "passage_keywords = [\n",
    "    \"passant par\",\n",
    "    \"via\",\n",
    "    \"par le chemin de\",\n",
    "    \"par la route de\",\n",
    "    \"par la voie de\",\n",
    "    \"en faisant un détour par\",\n",
    "    \"par l'intermédiaire de\",\n",
    "    \"en incluant\",\n",
    "    \"avec un arrêt à\",\n",
    "    \"parmi les étapes à\",\n",
    "    \"en traversant\",\n",
    "    \"en faisant escale à\",\n",
    "    \"tout en visitant\",\n",
    "    \"parmi les destinations à\",\n",
    "    \"et en découvrant\",\n",
    "    \"tout en passant par\",\n",
    "    \"tout en explorant\",\n",
    "    \"avec un passage à\",\n",
    "    \"en chemin vers\",\n",
    "    \"en voyage vers\"\n",
    "]\n",
    "# Liste des mots a exclure\n",
    "exclude_words = [\n",
    "    \"gare\",\n",
    "    \"Gare\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECTION DU MICROPHONE\n",
    "\n",
    "sr.Microphone.list_microphone_names()\n",
    "micro = sr.Microphone(device_index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe audio from microphone in French\n",
    "# Listen waiting until the audio has an energy above recognizer_instance.energy_threshold\n",
    "with micro as source:\n",
    "    print(\"Speak!\")\n",
    "    audio_data = r.listen(source)\n",
    "    print(\"End!\")\n",
    "textVoice = r.recognize_google(audio_data, language=\"fr-FR\")\n",
    "print (\">\", textVoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des fonction necessaire au script\n",
    "# Fonction pour détecter la langue de la phrase\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        language = detect(text)\n",
    "        if language != 'fr':   \n",
    "            return True  # Vérifie si la langue détectée n'est pas le français\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Fonction pour extraire les informations pertinentes\n",
    "def extract_trip_info(text):\n",
    "\n",
    "    for mot in exclude_words:\n",
    "        text = text.replace(mot, '')\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    locs = []\n",
    "    result = []\n",
    "    \n",
    "    is_not_french = detect_language(text)\n",
    "    if is_not_french:\n",
    "        locs.append(\"NOT_FRENCH\")\n",
    "        return locs\n",
    " \n",
    "    for token in doc:\n",
    "        if token.ent_type_ == \"LOC\":\n",
    "            locs.append(token.text)\n",
    "    print(locs)\n",
    "    if not locs:  # Si la liste est vide\n",
    "            result.append('NOT_TRIP')\n",
    "\n",
    "    # Normalisation des mots-clés des destination\n",
    "    destination_keywords_normalized = [unidecode(keyword) for keyword in destination_keywords]\n",
    "\n",
    "    # Normalisation des mots-clés des depart\n",
    "    departure_keywords_normalized = [unidecode(keyword) for keyword in departure_keywords]\n",
    "\n",
    "   # Normalisation des mots-clés des passage\n",
    "    passage_keywords_normalized = [unidecode(keyword) for keyword in passage_keywords]\n",
    "\n",
    "\n",
    "    departure = None\n",
    "    destination = None\n",
    "    passage = None\n",
    "    departure_count = 0\n",
    "    destination_count = 0\n",
    "    passage_count = 0\n",
    "\n",
    "\n",
    "    # FOR permettant de trouver la ville de depart \n",
    "    for i, token in enumerate(doc):\n",
    "        # use unicode for text\n",
    "        text_unicode = token.text\n",
    "        if token.text in departure_keywords or text_unicode in departure_keywords or token.text in departure_keywords_normalized or text_unicode in departure_keywords_normalized and i < len(doc) - 1:\n",
    "            if doc[i + 1].text in locs:\n",
    "                departure = doc[i+1].text\n",
    "                destination_count += 1  \n",
    "\n",
    "    # FOR permettant de trouver la ville de destination   \n",
    "    for i, token in enumerate(doc):\n",
    "        # use unicode for text\n",
    "        text_unicode = unidecode(token.text)\n",
    "        if token.text in destination_keywords or text_unicode in destination_keywords or token.text in destination_keywords_normalized or text_unicode in destination_keywords_normalized and i > 0:\n",
    "            if doc[i + 1].text in locs:\n",
    "                destination = doc[i+1].text\n",
    "                departure_count += 1  \n",
    "\n",
    "    # FOR permettant de trouver la ville par la qu'elle on veut passer pour arriver a destination\n",
    "    for keyword in passage_keywords:\n",
    "        keyword_words = keyword.split()  \n",
    "        keyword_length = len(keyword_words)\n",
    "        for i in range(len(doc) - keyword_length + 1):\n",
    "            window = [token.text for token in doc[i:i+keyword_length]]\n",
    "            if window == keyword_words:\n",
    "                passage_start = i + keyword_length\n",
    "                passage_end = passage_start + 1\n",
    "                if doc[passage_start:passage_end].text in locs:\n",
    "                    passage = doc[passage_start:passage_end].text\n",
    "                    passage_count += 1 \n",
    "                    break\n",
    "\n",
    "    if departure and destination and departure_count == 1 and destination_count == 1 and passage_count == 0 :\n",
    "        result = {\"DEPARTURE\": departure, \"DESTINATION\": destination}\n",
    "    elif departure and destination and passage and departure_count == 1 and destination_count == 1 and passage_count == 1:\n",
    "        result = {\"DEPARTURE\": departure,\"BETWEEN\" : passage, \"DESTINATION\": destination}\n",
    "    if (departure_count > 1) or (destination_count > 1):\n",
    "        result = {'NOT_TRIP'}\n",
    "        \n",
    "    return result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperation des depart destination et passage\n",
    "result = extract_trip_info(textVoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new Recognizer instance, which represents a collection of speech recognition functionality.\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Microsoft Sound Mapper - Input', 'Microphone (TONOR TC30 Audio De', 'VoiceMeeter Output (VB-Audio Vo', 'Microsoft Sound Mapper - Output', 'Speakers (4- High Definition Au', 'VoiceMeeter Input (VB-Audio Voi', 'Casque (Oculus Virtual Audio De', 'VG245 (NVIDIA High Definition A', 'LG ULTRAGEAR (NVIDIA High Defin', 'Pilote de capture audio principal', 'Microphone (TONOR TC30 Audio Device)', 'VoiceMeeter Output (VB-Audio VoiceMeeter VAIO)', 'PÃ©riphÃ©rique audio principal', 'Speakers (4- High Definition Audio Device)', 'VoiceMeeter Input (VB-Audio VoiceMeeter VAIO)', 'Casque (Oculus Virtual Audio Device)', 'VG245 (NVIDIA High Definition Audio)', 'LG ULTRAGEAR (NVIDIA High Definition Audio)', 'VoiceMeeter Input (VB-Audio VoiceMeeter VAIO)', 'Casque (Oculus Virtual Audio Device)', 'Speakers (4- High Definition Audio Device)', 'VG245 (NVIDIA High Definition Audio)', 'LG ULTRAGEAR (NVIDIA High Definition Audio)', 'Microphone (TONOR TC30 Audio Device)', 'VoiceMeeter Output (VB-Audio VoiceMeeter VAIO)', 'Output 1 (OCULUSVAD Wave Speaker Headphone)', 'Output 2 (OCULUSVAD Wave Speaker Headphone)', 'Input (OCULUSVAD Wave Speaker Headphone)', 'Headset Microphone (OCULUSVAD Wave Microphone Headphone)', 'Speakers (HD Audio Speaker)', 'VoiceMeeter Output (VoiceMeeter vaio)', 'Speakers (VoiceMeeter vaio)', 'Output (NVIDIA High Definition Audio)', 'Output (NVIDIA High Definition Audio)', 'Microphone (TONOR TC30 Audio Device)']\n"
     ]
    }
   ],
   "source": [
    "# Returns a list of the names of all available microphones. For microphones where the name can't be retrieved, the list entry contains None instead.\n",
    "sr.Microphone.list_microphone_names()\n",
    "print(sr.Microphone.list_microphone_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro = sr.Microphone(device_index=1) # my microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\33668\\Desktop\\T-AIA-901-NLP\\speech-to-text\\script.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/33668/Desktop/T-AIA-901-NLP/speech-to-text/script.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m micro \u001b[39mas\u001b[39;00m source:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/33668/Desktop/T-AIA-901-NLP/speech-to-text/script.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSpeak!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/33668/Desktop/T-AIA-901-NLP/speech-to-text/script.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     audio_data \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mlisten(source)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/33668/Desktop/T-AIA-901-NLP/speech-to-text/script.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEnd!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/33668/Desktop/T-AIA-901-NLP/speech-to-text/script.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m result \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mrecognize_google(audio_data, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfr-FR\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\33668\\Desktop\\T-AIA-901-NLP\\NLP\\lib\\site-packages\\speech_recognition\\__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[39mif\u001b[39;00m phrase_time_limit \u001b[39mand\u001b[39;00m elapsed_time \u001b[39m-\u001b[39m phrase_start_time \u001b[39m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    521\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mread(source\u001b[39m.\u001b[39;49mCHUNK)\n\u001b[0;32m    524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    525\u001b[0m frames\u001b[39m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\33668\\Desktop\\T-AIA-901-NLP\\NLP\\lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mread(size, exception_on_overflow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\33668\\Desktop\\T-AIA-901-NLP\\NLP\\lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Transcribe audio from microphone in French\n",
    "# Listen waiting until the audio has an energy above recognizer_instance.energy_threshold\n",
    "with micro as source:\n",
    "    print(\"Speak!\")\n",
    "    audio_data = r.listen(source)\n",
    "    print(\"End!\")\n",
    "result = r.recognize_google(audio_data, language=\"fr-FR\")\n",
    "print (\">\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
